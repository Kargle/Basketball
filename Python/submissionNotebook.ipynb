{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data import *\n",
    "from models import *\n",
    "from simulation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "Every March, Americans gather around their television sets for one of the most exciting playoffs in all of sports, the NCAA Division 1 Men's Basketball Finals, or March Madness. The \"Madness\" part of the coloquial name comes from the large field and single elimination structure of the tournament, in which ill-regarded teams often make deep runs, knocking off favorites as they advance. In the weeks leading up to the tournament each year, the millions try to predict the madness, picking winners for each of the tournament's 63+ games, hoping to become the first to have a perfect bracket and win a large sum. \n",
    "\n",
    "The most obvious strategy for picking winners is to simply pick the higher seeded team whenever possible, flipping a coin when two equal-seeded teams go head-to-head. Not only is this not a very fun strategy, but history has also shown that the best brackets deviate from this method, often quite dramatically. My goal with this project is to try to beat the boring-but-obvious method, and in the process, determine which factors and stats go into team success in March Madness, thus shedding a little light on the \"Madness\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Materials & Methods**\n",
    "\n",
    "In order to determine which factors contribute to a team's success in March Madness, I ran variable selection on a logistic regression model that included a wide range of team statistics. The dependent variable for the regression was game outcome (either win or lose). The independent variables appear below, along with a short description of each. Note that each of them represents the difference in one team's stat and their opponent's (i.e. <i>SeedDif</i> is the difference between the two teams tournament seeds (this can be a negative value)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SeedDif :  Difference in seeds\nRecordDif :  Difference in record\nPtsPGDif :  Difference in points per game\nPtsPGDifDif :  Difference in points per game differential\nTrueShtPercDif :  Difference in true shooting percentage\nORPGDif :  Difference in offensive rebounds per game\nDRPGDif :  Difference in defensive rebounds per game\nAstPGDif :  Difference in assists per game\nStlPGDif :  Difference in steals per game\nBlkPGDif :  Difference in blocks per game\nTOPGDif :  Difference in turnovers per game\nATRDif :  Difference in assist to turnover ratio\nPFPGDif :  Difference in personal fouls per game\nFTAPGDif :  Difference in free throw attempts per game\nDefMetricDif :  Difference in defensive metric (combination of blk, stl, DR, and PF) per game\nConfAppDif :  Difference in conference appearances\n"
    }
   ],
   "source": [
    "for i in range(len(xVariables)):\n",
    "    print(xVariables[i], ': ', xVariablesDesc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable selection employed AIC for model comparisons, and ran until improvement was no longer significant. Due to the random nature of train/test segmentation, as well as the relatively small sample size (1,115 games played from 2003 - 2019), the variable selection was run 1,000 times, and the frequency with which each variable was selected was reported.\n",
    "\n",
    "Using the results of the variable selection, I created several models using combinations of the variables and compared their predictions for historical tournament games to the actual outcomes of those games. I then compared the success rate of the models to the success rate of the \"higher-seed-always-wins\" technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "The (sorted) results of the variable selection runs appear below (the number next to each variable represents the ratio with which it was selected):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = logisticSelectMulti(yVariable, xVariables, logRegDF, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "DRPGDif 0.58\nStlPGDif 0.573\nFTAPGDif 0.562\nAstPGDif 0.554\nTrueShtPercDif 0.543\nPtsPGDif 0.541\nDefMetricDif 0.526\nATRDif 0.519\nPFPGDif 0.516\nTOPGDif 0.515\nBlkPGDif 0.509\nORPGDif 0.497\nRecordDif 0.426\nConfAppDif 0.373\nPtsPGDifDif 0.367\nSeedDif 0.284\n"
    }
   ],
   "source": [
    "sortedFreq = sorted(freq, reverse = True)\n",
    "sortedVars = [x for _, x in sorted(zip(freq, xVariables), reverse = True)]\n",
    "\n",
    "for i in range(len(freq)):\n",
    "    print(sortedVars[i], sortedFreq[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results from the variable selection, as well as my own knowledge about the sport, I created several potential logistic regression models and tested each against the \"better-seed-wins\" strategy. The results appear below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Better seed wins (baseline):  0.6313901345291479\nFull model (using all variables):  0.6556053811659193\nBest model (using curated variables):  0.6502242152466368\n"
    }
   ],
   "source": [
    "highSeedWinsAcc = tourneySimVsActual(list(range(2003, 2020)), highSeedWins, masterCompact)\n",
    "fullModelAcc = tourneySimVsActual(list(range(2003, 2020)), logRegPredictFull, masterDetailed)\n",
    "fullModelAccJr = tourneySimVsActual(list(range(2003, 2020)), logRegPredictFullJr, masterDetailed)\n",
    "\n",
    "print('Better seed wins (baseline): ', highSeedWinsAcc)\n",
    "print('Full model (using all variables): ', fullModelAcc)\n",
    "print('Best partial model (best result using fewest variables): ', fullModelAccJr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winner-picking success rate of baseline, seed-based model is ~63% (this moves around a little due to the \"flip a coin\" tie-breaker randomness). The full model, using all the variables from above, predicts games at 65.56% accuracy, a slight but not insignificant gain over the baseline. Arguably the most useful model is the best-performing partial model, which uses 12 of the 16 variables in the full model, but retains almost all of the accuracy of the full model, with 65.02%. This model includes the following variables, which seem to be the most useful for predicting tournament success:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "NumSeedDif\nRecordDif\nPtsPGDif\nPtsPGDifDif\nTrueShtPercDif\nORPGDif\nDRPGDif\nAstPGDif\nStlPGDif\nBlkPGDif\nTOPGDif\nATRDif\n"
    }
   ],
   "source": [
    "for i in chosenFeatures:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the most important statistical elements of team success identified, the \"Madness\" has receded a bit, and hopefully more enjoyment and understanding can be found in both predicting and watching the annual tournament as a result."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitanaconda3virtualenvbfa5aa89ad4a4a17a8c8a14bdb5884cf",
   "display_name": "Python 3.7.3 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}